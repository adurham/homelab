# Quick Start: Get Running in 5 Minutes âš¡

## Prerequisites

- âœ… VSCode with Continue.dev extension
- âœ… LM Studio installed
- âœ… Docker Desktop (for MCP servers)
- âœ… M4 MacBook Pro 36GB RAM

## Steps

### 1. Download Models (2-3 min)

In **LM Studio**, download:
- **qwen/qwen3-coder-30b** (primary)
- **qwen/qwen2.5-coder-32b** (backup)
- Optional: **mlx-community/deepseek-coder-33b-instruct-hf-4bit-mlx**

**How**: LM Studio â†’ Search â†’ Search name â†’ Download

### 2. Start LM Studio Server (30 sec)

1. LM Studio â†’ "Local Server" tab
2. Click "Start Server"
3. Load a model (double-click)
4. âœ… Server runs on `http://localhost:1234/v1`

### 3. Copy Config (10 sec)

```bash
cp "misc scripts/continue-dev/continue-config.yaml" ~/.continue/config.yaml
```

### 4. Start Docker (optional, 30 sec)

1. Open Docker Desktop
2. Wait for it to start
3. MCP servers auto-connect

### 5. Restart VSCode (10 sec)

1. Quit VSCode completely (Cmd+Q)
2. Reopen VSCode
3. Open Continue chat (Cmd+L)

## ðŸŽ‰ Done! Try It

Open Continue and type:
- `/cursor-agent` - Smart agent
- Ask about your code
- Use `@code` to search codebase

## Optional: Add Cloud API Keys

Create `~/.continue/.env`:
```bash
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
VOYAGE_API_KEY=pa-...
```

Get keys: [Anthropic](https://console.anthropic.com/) | [OpenAI](https://platform.openai.com/) | [Voyage](https://www.voyageai.com/)

## What You Got

âœ… 4 local models (free, fast, private)  
âœ… 2 cloud models (optional, paid)  
âœ… Smart commands (`/cursor-agent`, `/cloud-architect`, etc.)  
âœ… MCP servers for enhanced capabilities  
âœ… Context providers (`@code`, `@file`, `@tree`, etc.)

## Troubleshooting

**LM Studio not connecting?**  
â†’ Check server is running, verify `http://localhost:1234/v1`

**Models not showing?**  
â†’ Verify model names, restart VSCode

**Need help?**  
â†’ See `README.md` for detailed guide

---

**Next**: Read `README.md` for full setup details | `USAGE_TIPS.md` for best practices
