# Tanium Download Performance Analysis - Complete Metrics Guide

## Overview

This comprehensive guide explains how to use **`analyze_tanium_pcaps.py`** to diagnose Tanium CDN vs Legacy download performance issues.

### What This Guide Covers

- **Tool**: `analyze_tanium_pcaps.py` - The packet capture analysis script
- **Input**: PCAPs generated by `tanium_download_perf_test.py`
- **Purpose**: Compare CDN vs Legacy download performance and identify throttling

### Expected PCAP Structure

The analysis script expects PCAPs from the performance test tool:

```bash
# Generate PCAPs using the performance test
python3 tanium_download_perf_test.py

# This creates a directory with PCAPs:
tanium_pcaps_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ legacy_iteration_1.pcap
‚îú‚îÄ‚îÄ legacy_iteration_2.pcap
‚îú‚îÄ‚îÄ legacy_iteration_3.pcap
‚îú‚îÄ‚îÄ legacy_iteration_4.pcap
‚îú‚îÄ‚îÄ legacy_iteration_5.pcap
‚îú‚îÄ‚îÄ cdn_iteration_1.pcap
‚îú‚îÄ‚îÄ cdn_iteration_2.pcap
‚îú‚îÄ‚îÄ cdn_iteration_3.pcap
‚îú‚îÄ‚îÄ cdn_iteration_4.pcap
‚îî‚îÄ‚îÄ cdn_iteration_5.pcap

# Analyze the PCAPs
python3 analyze_tanium_pcaps.py --pcap-dir tanium_pcaps_YYYYMMDD_HHMMSS/
```

**File naming requirements:**
- Files containing `legacy` are categorized as Legacy server downloads (port 17472)
- Files containing `cdn` are categorized as CDN downloads (port 443)
- Multiple iterations (typically 5 each) for statistical significance

This guide explains TCP fundamentals, every metric measured, the mathematics behind calculations, and how to interpret results.

---

## Table of Contents

1. [TCP Fundamentals](#tcp-fundamentals)
2. [Download Scenarios Explained](#download-scenarios-explained)
3. [Metric Categories](#metric-categories)
4. [Basic Statistics](#basic-statistics)
5. [Connection Establishment](#connection-establishment)
6. [Round-Trip Time (RTT)](#round-trip-time-rtt)
7. [Packet Loss & Retransmissions](#packet-loss--retransmissions)
8. [TCP Flow Control & Issues](#tcp-flow-control--issues)
9. [Throughput Analysis](#throughput-analysis)
10. [Root Cause Metrics](#root-cause-metrics)
    - [Server Response Latency](#server-response-latency)
    - [Inter-Packet Delays](#inter-packet-delays)
    - [Burst Pattern Analysis](#burst-pattern-analysis)
    - [Pacing Precision Analysis](#pacing-precision-analysis)
11. [Statistical Methods](#statistical-methods)
12. [Diagnosis Logic](#diagnosis-logic)
13. [Rate Limiting Algorithms](#rate-limiting-algorithms)
14. [CDN vs Legacy Comparison](#cdn-vs-legacy-comparison)
15. [Case Studies](#case-studies)
16. [Troubleshooting Guide](#troubleshooting-guide)
17. [Appendix: Technical Details](#appendix-technical-details)

---

## TCP Fundamentals

Before diving into metrics, let's establish TCP basics relevant to this analysis.

### TCP Connection Model

In a download scenario:
- **Client**: Initiates connection, receives data (Tanium client)
- **Server**: Accepts connection, sends data (Legacy server or CDN)
- **Download**: Server ‚Üí Client data transfer (server srcport, client dstport)
- **ACKs**: Client ‚Üí Server acknowledgments (client srcport, server dstport)

### TCP Window and Flow Control

**TCP Windows control data flow:**

1. **Receive Window** (advertised by receiver):
   - "I can receive X bytes before my buffer fills"
   - Receiver advertises this in every packet
   - In downloads: **Client advertises** its receive window

2. **Congestion Window** (sender's internal state):
   - "I will send X bytes before waiting for ACK"
   - Not visible in packets (internal TCP state)
   - Sender manages this based on network conditions

**Key Insight:** In a download, the **client's window** matters because it limits how much data the server can send. The **server's window** is largely irrelevant because the client only sends small ACKs.

### TCP Packet Structure

```
Ethernet | IP | TCP Header | TCP Data
                   |
                   +-- Source Port
                   +-- Dest Port
                   +-- Sequence Number
                   +-- ACK Number
                   +-- Flags (SYN, ACK, FIN, RST, PSH)
                   +-- Window Size
                   +-- Checksum
```

### What We Can Measure

From packet captures we can see:
- **Timing**: When packets are sent/received
- **Size**: How much data in each packet
- **Sequence numbers**: Order and retransmissions
- **Window sizes**: Flow control state
- **Flags**: Connection state and issues

What we **cannot** see directly:
- Server CPU/memory usage
- Application-level decisions
- Why the server chose specific timing

**But** we can **infer** server behavior from timing patterns.

---

## Download Scenarios Explained

### Scenario: Legacy Server Download

```
Client                           Legacy Server (port 17472)
  |                                     |
  |--- SYN ------------------------->  |
  |<-- SYN-ACK ---------------------   |
  |--- ACK ------------------------->  |
  |--- GET /file -------------------->  |
  |                                     |
  |<== DATA DATA DATA DATA DATA DATA == | (Continuous stream)
  |<== DATA DATA DATA DATA DATA DATA == |
  |<== DATA DATA DATA DATA DATA DATA == |
  |--- ACK ACK ACK ------------------>  |
  |<== DATA DATA DATA DATA DATA DATA == |
  |                                     |
```

**Characteristics:**
- Server sends data **continuously**
- Minimal gaps between packets (~0.1-1ms)
- Full-sized packets (1460 bytes TCP data)
- Smooth, consistent throughput

### Scenario: Throttled CDN Download

```
Client                           CDN Server (port 443)
  |                                     |
  |--- SYN ------------------------->  |
  |<-- SYN-ACK ---------------------   |
  |--- ACK ------------------------->  |
  |--- GET /file -------------------->  |
  |                                     |
  |<== DATA DATA DATA === [20ms gap]   | (Burst 1)
  |<== DATA DATA DATA === [20ms gap]   | (Burst 2)
  |<== DATA DATA DATA === [20ms gap]   | (Burst 3)
  |--- ACK ACK ACK ------------------>  |
  |<== DATA DATA DATA === [20ms gap]   | (Burst 4)
  |                                     |
```

**Characteristics:**
- Server sends in **bursts** with gaps
- Consistent gap timing (~20ms between bursts)
- Each burst has 3-5 packets
- Highly variable throughput

**This is the smoking gun for throttling.**

---

## Metric Categories

We organize metrics into three categories:

### 1. Outcome Metrics (What Happened)
- Basic statistics (throughput, duration, bytes)
- Throughput over time

**Purpose:** Quantify the performance problem

### 2. Network Metrics (Path Quality)
- RTT (network latency)
- Packet loss (retransmissions)
- TCP flags (connection issues)

**Purpose:** Rule out network as the bottleneck

### 3. Root Cause Metrics (Why It Happened)
- Inter-packet delays
- Burst patterns
- Pacing precision
- Server response latency

**Purpose:** Identify server-side throttling behavior

---

## Basic Statistics

### Metrics Collected

```python
{
  "total_packets": 8532,
  "duration_seconds": 45.23,
  "total_bytes": 12582912,
  "avg_throughput_mbps": 2.23
}
```

### Calculations

**Average Throughput:**
```
Throughput (Mbps) = (total_bytes √ó 8) / (duration_seconds √ó 1,000,000)
```

Example:
```
12,582,912 bytes √ó 8 bits/byte = 100,663,296 bits
100,663,296 / (45.23 √ó 1,000,000) = 2.23 Mbps
```

### Implementation Details

We use tshark to extract:
```bash
tshark -r file.pcap -T fields -Y tcp \
  -e frame.number \
  -e frame.time_relative \
  -e frame.len
```

This gives us:
- Frame number (packet count)
- Relative timestamp (duration = last timestamp)
- Frame length (sum = total bytes)

### What This Tells Us

**Throughput interpretation:**
- **>100 Mbps**: Good, server/network performing well
- **50-100 Mbps**: Moderate, some limitation
- **20-50 Mbps**: Poor, significant bottleneck
- **<20 Mbps**: Very poor, major issue

**But this is just the outcome.** We need other metrics to know WHY.

### CDN vs Legacy Expected Values

Typical observations:
- Legacy: 100-200 Mbps (wire speed, minimal delays)
- CDN (throttled): 20-60 Mbps (rate limited)

**Red flag:** If CDN throughput is <50% of Legacy, investigate root causes.

---

## Connection Establishment

### What We Measure

The **TCP three-way handshake** timing:

```
Client                Server
  |                     |
  |--- SYN -----------> | (t0)
  |<-- SYN-ACK -------- | (t1)
  |--- ACK -----------> | (t2)
```

**Handshake Time** = t1 - t0 (SYN to SYN-ACK)

### Metrics Collected

```python
{
  "handshake_time_ms": 12.34,
  "syn_time": 0.0,
  "synack_time": 0.01234
}
```

### Why This Matters

Handshake time tells us:
- **Network latency**: Minimum ~RTT/2 for the path
- **Server responsiveness**: How quickly server accepts connections
- **Connection overhead**: Fixed cost before any data transfer

### Interpretation

- **<10ms**: Excellent, low latency path
- **10-30ms**: Good, typical for regional connections
- **30-100ms**: Moderate, geographic distance or routing
- **>100ms**: High latency, international or routing issues

### Implementation

```bash
tshark -r file.pcap -T fields -Y "tcp.flags.syn == 1" \
  -e frame.time_relative \
  -e tcp.flags.syn \
  -e tcp.flags.ack
```

We look for:
1. First packet with SYN=1, ACK=0 (client SYN)
2. Next packet with SYN=1, ACK=1 (server SYN-ACK)

### CDN vs Legacy

Both should have similar handshake times (¬±5ms) unless:
- CDN endpoint is geographically distant
- CDN load balancing adds overhead
- Network routing differs significantly

**If handshake times are similar but throughput differs**, the issue is NOT connection establishment.

---

## Round-Trip Time (RTT)

### What RTT Measures

**Round-Trip Time** is the time for:
```
Client --- packet ---> Server
Client <-- response -- Server
```

Total time: forward propagation + server processing + return propagation

### How TCP Calculates RTT

TCP automatically tracks RTT using:
1. **Segment sent** at time T1
2. **ACK received** at time T2
3. **RTT = T2 - T1**

This is visible in packet captures through tshark's `tcp.analysis.ack_rtt` field.

### Metrics Collected

```python
{
  "samples": 1247,
  "min_ms": 8.23,
  "max_ms": 156.42,
  "avg_ms": 12.45,
  "median_ms": 11.89,
  "stddev_ms": 8.34,
  "p95_ms": 24.67,
  "p99_ms": 45.23
}
```

### Statistical Significance

**Why we use percentiles:**

- **Average**: Can be skewed by outliers
- **Median**: Middle value, more stable
- **P95**: 95% of RTTs are below this (good for SLAs)
- **P99**: Worst-case excluding extreme outliers

**Standard deviation** tells us how variable RTT is:
- Low stddev (< 5ms): Stable path
- High stddev (> 20ms): Variable latency (bufferbloat, queueing)

### Implementation

```bash
tshark -r file.pcap -T fields -Y "tcp.analysis.ack_rtt" \
  -e frame.time_relative \
  -e tcp.analysis.ack_rtt
```

We collect all RTT samples and calculate statistics.

### Interpreting RTT Results

**Absolute values:**
- **<20ms**: Excellent (same datacenter or metro area)
- **20-50ms**: Good (regional)
- **50-100ms**: Moderate (cross-country)
- **>100ms**: High (international or satellite)

**Variability (stddev/mean as %):**
- **<10%**: Very stable
- **10-30%**: Normal variation
- **30-50%**: Moderate bufferbloat
- **>50%**: Severe queueing issues

### RTT vs Throughput

**Key insight:** RTT and throughput are related but not the same.

**Example 1: High RTT, Good Throughput**
```
RTT: 80ms (US East to US West)
Throughput: 150 Mbps
Diagnosis: High latency due to distance, but bandwidth is good
```

**Example 2: Low RTT, Poor Throughput**
```
RTT: 12ms (same region)
Throughput: 25 Mbps
Diagnosis: NOT a latency issue, something else is limiting throughput
```

### CDN vs Legacy Comparison

**If RTT is similar:**
```
Legacy RTT: 12.3ms (¬±2.1)
CDN RTT: 13.5ms (¬±2.4)
```

**Conclusion:** Network path quality is similar. If CDN throughput is still poor, the issue is **NOT network latency**.

**If RTT differs significantly:**
```
Legacy RTT: 12.3ms (¬±2.1)
CDN RTT: 78.4ms (¬±5.6)
```

**Conclusion:** CDN endpoint may be geographically distant. But this alone doesn't explain low throughput if TCP windows are adequate.

### Why RTT Alone Doesn't Explain Throttling

With modern TCP (window scaling, SACK, etc.):
- **Even 100ms RTT** should achieve 100+ Mbps with proper window sizes
- **TCP can saturate high-latency links** if allowed to

If throughput is poor despite adequate windows, look at **server sending behavior**.

---

## Packet Loss & Retransmissions

### What Retransmissions Mean

TCP is reliable - if a packet is lost, it's retransmitted.

**Types of retransmissions:**

1. **Fast Retransmission**: After 3 duplicate ACKs, sender assumes loss
2. **Timeout Retransmission**: After RTO (Retransmission Timeout) expires
3. **Spurious Retransmission**: False positive (packet wasn't actually lost)

### Metrics Collected

```python
{
  "total_retransmissions": 23,
  "fast_retransmissions": 18,
  "spurious_retransmissions": 2,
  "total_tcp_packets": 8532,
  "retransmission_rate_pct": 0.270
}
```

### Calculating Retransmission Rate

```
Retransmission Rate (%) = (retransmissions / total_tcp_packets) √ó 100
```

Example:
```
23 retransmissions / 8532 packets = 0.270%
```

### Interpretation

**Retransmission rate thresholds:**
- **<0.5%**: Excellent, negligible loss
- **0.5-1.0%**: Good, minor loss
- **1.0-3.0%**: Moderate, noticeable impact
- **>3.0%**: Poor, significant packet loss

### Impact on Performance

**Each retransmission:**
- Delays data delivery by 1-3√ó RTT
- May trigger congestion control (window reduction)
- Reduces effective throughput

**Throughput reduction estimate:**
```
Effective Throughput ‚âà Ideal Throughput √ó (1 - RetransRate)
```

Example:
```
Ideal: 100 Mbps
Retrans Rate: 3%
Effective: 100 √ó (1 - 0.03) = 97 Mbps
```

### Root Causes of Packet Loss

1. **Network congestion**: Routers drop packets when queues fill
2. **Physical issues**: Bad cables, interference
3. **Firewall/middlebox**: Stateful tracking issues
4. **Buffer overflow**: Receiver or intermediate buffers full

### Implementation

```bash
# Count retransmissions
tshark -r file.pcap -Y "tcp.analysis.retransmission" -T fields -e frame.number

# Count fast retransmissions
tshark -r file.pcap -Y "tcp.analysis.fast_retransmission" -T fields -e frame.number

# Count spurious
tshark -r file.pcap -Y "tcp.analysis.spurious_retransmission" -T fields -e frame.number
```

### CDN vs Legacy Comparison

**Scenario 1: Both have low loss**
```
Legacy: 0.23% retransmissions
CDN: 0.19% retransmissions
```
**Conclusion:** Network paths are both healthy. Retransmissions not the issue.

**Scenario 2: CDN has high loss**
```
Legacy: 0.23% retransmissions
CDN: 3.45% retransmissions
```
**Conclusion:** CDN network path has issues. Could be:
- Routing through congested path
- Firewall dropping packets
- CDN infrastructure overload

**This would be a contributing factor, but check if burst pacing is also present.**

### Relationship to Throttling

**Important:** Throttling and packet loss are **separate issues**.

- Throttling = server deliberately delays sending
- Packet loss = network drops packets

You can have:
- Throttling with no loss (typical for CDN rate limiting)
- Loss with no throttling (network congestion)
- Both (unlucky combination)

---

## TCP Flow Control & Issues

### What We Measure

TCP has built-in flow control mechanisms that can indicate problems:

1. **Duplicate ACKs**: Receiver asking for retransmission
2. **Zero Windows**: Receiver buffer full, can't accept data
3. **Resets (RST)**: Connection aborted

### Metrics Collected

```python
{
  "resets": 0,
  "duplicate_acks": 12,
  "zero_windows": 0
}
```

### Duplicate ACKs

**What it means:**
- Receiver got out-of-order packet (gap detected)
- Sends duplicate ACK to signal gap
- After 3 duplicate ACKs ‚Üí fast retransmission

**Interpretation:**
- **<10**: Normal, minor reordering
- **10-50**: Moderate packet loss/reordering
- **>50**: Significant network issues

**In our context:**
Moderate duplicate ACKs suggest packet loss (see retransmission section).

### Zero Windows

**What it means:**
- Receiver advertises window size = 0
- Receiver buffer is full
- Sender must stop sending until window opens

**Causes:**
- Receiver application not reading data fast enough
- Receiver CPU/memory constrained
- Receiver disk I/O slow

**Interpretation:**
- **0 zero windows**: Receiver keeping up fine
- **1-5**: Brief receiver stalls
- **>5**: Receiver is bottleneck

**In downloads:**
Zero windows on **client** side would indicate:
- Tanium client can't write to disk fast enough
- Client CPU overloaded
- Client buffer management issue

This would limit throughput regardless of server behavior.

### TCP Resets

**What it means:**
- Connection terminated abruptly
- Either side can send RST

**Causes:**
- Firewall killing connection
- Application crash
- Protocol violation
- Port scan detection

**Interpretation:**
- **0 resets**: Clean connection
- **1 reset at end**: Normal close (some implementations)
- **Multiple resets**: Connection instability

### Implementation

```bash
# Duplicate ACKs
tshark -r file.pcap -Y "tcp.analysis.duplicate_ack" -T fields -e frame.number

# Zero windows
tshark -r file.pcap -Y "tcp.analysis.zero_window" -T fields -e frame.number

# Resets
tshark -r file.pcap -Y "tcp.flags.reset == 1" -T fields -e frame.number
```

### CDN vs Legacy

These metrics should be **similar and low** for both if everything is healthy.

**Red flags:**
- CDN has many zero windows: CDN or client receiving issues
- CDN has many resets: Connection instability
- High duplicate ACKs: Network path issues

But these are typically **not the main issue** in throttling scenarios.

---

## Throughput Analysis

### Throughput Over Time

Instead of just average throughput, we measure **how throughput varies** during the transfer.

### Methodology

1. **Divide transfer into time intervals** (default: 1 second)
2. **Sum bytes in each interval**
3. **Calculate throughput per interval**
4. **Analyze distribution**

### Metrics Collected

```python
{
  "interval_seconds": 1,
  "intervals": [
    {"interval": 0, "time_start": 0, "time_end": 1, "bytes": 12582912, "mbps": 100.66},
    {"interval": 1, "time_start": 1, "time_end": 2, "bytes": 11534336, "mbps": 92.27},
    ...
  ],
  "stats": {
    "min_mbps": 15.23,
    "max_mbps": 145.67,
    "avg_mbps": 87.34,
    "median_mbps": 92.11,
    "stddev_mbps": 24.56
  }
}
```

### Calculating Interval Throughput

```python
# For each time interval
bytes_in_interval = sum(packet_sizes where interval_start <= packet_time < interval_end)
mbps = (bytes_in_interval √ó 8) / (interval_seconds √ó 1,000,000)
```

### Throughput Variability Analysis

**Coefficient of Variation (CoV):**
```
CoV = (stddev / mean) √ó 100%
```

**Interpretation:**
- **<10%**: Very consistent throughput
- **10-30%**: Normal variation (TCP dynamics)
- **30-50%**: Moderate variability
- **>50%**: Highly variable (likely throttling or severe network issues)

### Throughput Patterns

**Pattern 1: Consistent (Healthy)**
```
Time (s):  0    1    2    3    4    5
Mbps:    100  102   98  101   99  100
```
Low CoV (~2%), stable sending.

**Pattern 2: Slow Start (Normal TCP)**
```
Time (s):  0    1    2    3    4    5
Mbps:     20   45   85  100  100  100
```
Increases then stabilizes. Normal TCP congestion control.

**Pattern 3: Throttled/Bursty**
```
Time (s):  0    1    2    3    4    5
Mbps:     80   30   85   25   80   30
```
High CoV (~60%), alternating high/low. **Smoking gun for throttling.**

**Pattern 4: Degrading**
```
Time (s):  0    1    2    3    4    5
Mbps:    100   90   75   60   45   30
```
Progressive decrease. Could be buffer filling, congestion, or server slowdown.

### Implementation

```bash
tshark -r file.pcap -T fields \
  -Y "tcp.srcport == SERVER_PORT and tcp.len > 0" \
  -e frame.time_relative \
  -e tcp.len
```

We group packets by time interval and sum TCP payload bytes.

### CDN vs Legacy Patterns

**Typical Legacy pattern:**
```
Stats: avg=145 Mbps, stddev=12 Mbps, CoV=8%
Pattern: Consistent, smooth
```

**Typical CDN throttled pattern:**
```
Stats: avg=45 Mbps, stddev=28 Mbps, CoV=62%
Pattern: Bursty, high variation
```

**Visualization:**
```
Legacy Throughput Over Time:
150 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
120 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
 90 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
 60 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
 30 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
     0    5   10   15   20   25   30   35

CDN Throughput Over Time:
150 ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà
120 ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà    ‚ñà
 90 ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà
 60 ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà
 30 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
     0    5   10   15   20   25   30   35
```

High variability = throttling signature.

---

## Root Cause Metrics

These are the **key metrics** that identify WHY performance is poor.

---

## Server Response Latency

### What It Measures

**How long the server takes to respond after receiving a request.**

This is **NOT RTT** - it's measuring server-side processing and response initiation time.

### Methodology

1. **Client sends request** (e.g., HTTP GET) at time T1
2. **Server receives request** (approximately T1 + RTT/2)
3. **Server processes and sends data** at time T2
4. **Client receives first data** at T3

**Server Response Latency** ‚âà T3 - T1 - RTT

But in practice, we simplify by measuring time from client request to first server data packet.

### Example Scenario

```
T=0ms:   Client sends GET request
T=12ms:  Server receives request (RTT/2)
T=15ms:  Server processes, prepares response
T=20ms:  Server sends first data packet
T=32ms:  Client receives first data (RTT/2)

Server latency ‚âà 32ms - 0ms = 32ms
Or more accurately: 20ms - 12ms = 8ms processing time
```

### Metrics Collected

```python
{
  "samples": 156,
  "min_ms": 2.34,
  "max_ms": 45.67,
  "avg_ms": 8.23,
  "median_ms": 7.89,
  "p95_ms": 15.23,
  "p99_ms": 28.45,
  "stddev_ms": 6.78
}
```

### Implementation Details

```python
# Pseudocode
client_requests = []  # Packets TO server with TCP data
server_responses = []  # Packets FROM server with TCP data

for each server response at time T:
    find most recent client request before T
    latency = T - request_time
    if latency < 1000ms:  # Sanity check
        record latency
```

We match server data packets to preceding client requests.

### Interpretation

**Latency values:**
- **<5ms**: Excellent, server responds immediately
- **5-15ms**: Good, normal processing
- **15-50ms**: Moderate, some delay
- **>50ms**: High, server slow to respond

**What causes high latency:**
- Server processing overhead (encryption, compression)
- Server under load (CPU/memory pressure)
- Application-level delays (database queries, file I/O)
- Deliberate rate limiting (queuing requests)

### CDN vs Legacy

**Scenario 1: Similar latencies**
```
Legacy: 5.23ms avg
CDN: 6.78ms avg
```
**Conclusion:** Both respond quickly. Initial response not the bottleneck.

**Scenario 2: CDN slower to respond**
```
Legacy: 5.23ms avg
CDN: 42.34ms avg
```
**Conclusion:** CDN is slow to START sending data. Could be:
- CDN processing overhead
- CDN queuing requests
- Geographic distance
- CDN under load

### Relationship to Overall Performance

**Important:** Even if initial response is slow, sustained throughput could still be good IF the server sends continuously after starting.

**Example:**
```
Server latency: 50ms (slow start)
Inter-packet delay: 0.5ms (fast continuous sending)
Result: Brief initial delay, then good throughput
```

But if **both** server latency AND inter-packet delays are high, you have a comprehensive server-side bottleneck.

---

## Inter-Packet Delays

### ‚ö†Ô∏è PRIMARY ROOT CAUSE INDICATOR ‚ö†Ô∏è

This is the **most important metric** for diagnosing server-side throttling.

### What It Measures

**Time between consecutive data packets from the server.**

In a download, the server has data queued and ready to send. How fast does it actually send?

### Methodology

```python
# Get all data packets from server with timestamps
packets = get_packets(src_port=SERVER_PORT, tcp_len > 0)

# Calculate delays between consecutive packets
delays = []
for i in range(1, len(packets)):
    delay_ms = (packets[i].time - packets[i-1].time) * 1000
    delays.append(delay_ms)
```

### Example

```
Packet 1 sent at T=0.0000s
Packet 2 sent at T=0.0005s ‚Üí delay = 0.5ms
Packet 3 sent at T=0.0011s ‚Üí delay = 0.6ms
Packet 4 sent at T=0.0015s ‚Üí delay = 0.4ms
...
```

Average delay = 0.5ms ‚Üí 2000 packets/second ‚Üí smooth continuous sending

### Metrics Collected

```python
{
  "samples": 2456,
  "min_ms": 0.012,
  "max_ms": 125.45,
  "avg_ms": 15.234,
  "median_ms": 12.456,
  "p95_ms": 35.678,
  "p99_ms": 67.890,
  "stddev_ms": 18.234
}
```

### Why This Is Critical

**This measures server sending rate directly.**

The server has:
- Data in its send buffer (application layer)
- TCP send queue ready to go
- Network available (client ACKs received)

**If delays are large, the server is:**
- Deliberately pausing between sends (rate limiting)
- Slow to queue data (CPU/I/O bound)
- Using inefficient buffering

**This is NOT network latency** because the data is already queued. It's **server behavior**.

### Interpretation

**Delay thresholds:**
- **<0.5ms**: Excellent, wire-speed sending
- **0.5-2ms**: Good, fast continuous sending
- **2-5ms**: Moderate, some pauses
- **5-10ms**: Poor, noticeable delays
- **>10ms**: Very poor, severe throttling

### Real-World Examples

**Example 1: Unthrottled Server**
```
Average delay: 0.523ms
P95: 1.234ms
P99: 2.456ms

Interpretation: Server sending as fast as possible, continuous stream
```

**Example 2: Lightly Throttled Server**
```
Average delay: 3.456ms
P95: 8.123ms
P99: 15.234ms

Interpretation: Some pacing, but not severe
```

**Example 3: Heavily Throttled Server**
```
Average delay: 18.234ms
P95: 45.678ms
P99: 89.123ms

Interpretation: Severe pacing, clear rate limiting
```

### Statistical Analysis

**Coefficient of Variation:**
```
CoV = (stddev / mean) √ó 100%
```

- High CoV (>100%): Natural variation, bursty TCP
- Moderate CoV (50-100%): Some consistency
- Low CoV (<50%): Very consistent delays (algorithmic pacing)

### CDN vs Legacy Comparison

**The Smoking Gun:**

```
Legacy:
  Average: 0.523ms
  P95: 1.234ms
  Interpretation: Continuous sending

CDN:
  Average: 15.234ms
  P95: 35.678ms
  Ratio: 29.1x slower

Conclusion: CDN server is pausing 29x longer between packets.
           This is NOT network latency (RTT is similar).
           This IS server-side throttling.
```

**Ratio interpretation:**
- **1-2x**: Minor difference, acceptable
- **2-3x**: Noticeable slowdown
- **3-10x**: Significant throttling
- **>10x**: Severe throttling, clear rate limiting

### Why Small TCP Windows Are a Symptom

When the server sends slowly (large inter-packet delays):

1. **Client receives data slowly**
2. **Client's receive buffer doesn't fill**
3. **TCP advertises smaller window** (no need for large window)
4. **Server continues sending slowly** (rate limiter doesn't care about window)

The small window is TCP's **reaction** to slow data arrival, not the cause.

**Proof:** If you increase the client's window, the throughput **doesn't improve** because the server is still rate limiting.

### Relationship to Burst Patterns

Inter-packet delays and burst patterns are related:

**Continuous sending:**
```
Delays: 0.5, 0.6, 0.4, 0.5, 0.5, 0.6 ms
Pattern: Smooth, all delays similar
```

**Burst pacing:**
```
Delays: 0.5, 0.4, 0.6, 20.0, 0.5, 0.4, 0.5, 20.0 ms
Pattern: Fast packets (burst), then long gap, repeat
```

Average might be 5ms, but the **pattern** reveals throttling mechanism.

---

## Burst Pattern Analysis

### ‚ö†Ô∏è PRIMARY THROTTLING INDICATOR ‚ö†Ô∏è

This metric **proves algorithmic rate limiting** by detecting burst pacing patterns.

### What It Measures

**Does the server send data in bursts (with gaps) or continuously?**

- **Burst**: Group of packets sent very quickly (<10ms apart)
- **Gap**: Longer pause between bursts (>10ms)

### Methodology

```python
burst_threshold_ms = 10  # Define what's "fast" vs "gap"

delays = calculate_inter_packet_delays()
bursts = []
current_burst = []
gaps = []

for delay in delays:
    if delay < burst_threshold_ms:
        # Fast packet, part of current burst
        current_burst.append(packet)
    else:
        # Gap found - end current burst
        if current_burst:
            bursts.append(len(current_burst))
            gaps.append(delay)
            current_burst = []
```

### Visual Example

**Continuous sending (Legacy):**
```
Time: ||||||||||||||||||||||||||||||||||||||||
Pkts: ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè

Result: 1-2 large bursts (whole transfer is one stream)
```

**Burst pacing (Throttled CDN):**
```
Time: |   |   |   |   |   |   |   |   |   |   |
Pkts: ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè   ‚óè‚óè‚óè

Result: 8 bursts with ~20ms gaps between them
```

### Metrics Collected

```python
{
  "total_bursts": 675,
  "avg_burst_size": 4.3,
  "min_burst_size": 2,
  "max_burst_size": 12,
  "avg_gap_ms": 20.31,
  "total_packets": 2456
}
```

### Interpretation

**Burst count thresholds:**
- **<10 bursts**: Continuous sending, natural TCP
- **10-50 bursts**: Minor burst behavior
- **50-100 bursts**: Moderate burst pacing
- **>100 bursts**: Clear burst pacing, algorithmic throttling

**Gap timing:**
- **<5ms gaps**: Not really gaps, normal TCP variation
- **5-15ms gaps**: Moderate pacing
- **15-30ms gaps**: Clear pacing
- **>30ms gaps**: Severe pacing

### Why This Proves Throttling

**Natural TCP doesn't create hundreds of consistent bursts.**

Natural TCP might have:
- Initial slow start (one "burst" as cwnd increases)
- Occasional pauses for ACKs (if window fills)
- Random variation

But **500+ bursts with consistent ~20ms gaps** is:
- **Too consistent** to be network effects
- **Too frequent** to be ACK-based flow control
- **Too precise** to be organic TCP dynamics

**This is algorithmic behavior** - a rate limiter releasing data in controlled bursts.

### Rate Limiting Mechanism

Burst pacing typically indicates a **token bucket** algorithm:

```
Token Bucket Algorithm:
1. Bucket holds tokens (credits to send data)
2. Tokens added at fixed rate (e.g., 50 tokens/sec)
3. Each packet costs tokens
4. If bucket empty, wait until tokens accumulate
5. When tokens available, send burst of packets
```

This creates the burst-gap-burst-gap pattern.

### CDN vs Legacy Comparison

**Typical results:**

```
Legacy:
  Total bursts: 8
  Average gap: 125ms
  Interpretation: Essentially continuous, occasional ACK pauses

CDN:
  Total bursts: 675
  Average gap: 20.31ms
  Interpretation: 675 distinct burst-gap cycles

Ratio: 84x more bursts on CDN

Conclusion: CDN is using burst pacing rate limiting.
           This is NOT organic TCP behavior.
```

### Relationship to Throughput

**Impact of burst pacing:**

```
Example:
- Burst size: 5 packets √ó 1460 bytes = 7300 bytes
- Burst duration: ~1ms
- Gap duration: 20ms
- Cycle time: 21ms

Throughput = 7300 bytes / 0.021 seconds
          = 347,619 bytes/sec
          = 2.78 Mbps
```

Even though the server can send at 100+ Mbps during bursts, the gaps limit average throughput.

### Real-World Example

From actual PCAP analysis:

```
CDN Statistics:
  Total packets: 2456
  Total bursts: 675
  Average burst size: 3.6 packets
  Average gap: 20.31ms

Math:
  2456 packets / 675 bursts = 3.6 packets/burst ‚úì
  Total bursts √ó avg gap = 675 √ó 20.31ms = 13.7 seconds spent in gaps
  Transfer duration: 45 seconds
  Gap percentage: 13.7 / 45 = 30.4% of time spent in gaps

Conclusion: Server spends 30% of time paused, 70% sending.
           This explains low throughput despite good RTT.
```

---

## Pacing Precision Analysis

### ‚ö†Ô∏è ALGORITHMIC THROTTLING INDICATOR ‚ö†Ô∏è

This metric proves the delays are **programmatic, not natural**.

### What It Measures

**How uniform/precise are the inter-packet delays?**

Natural systems (TCP, network queues, CPUs) have inherent variation:
- CPU scheduling jitter (microseconds)
- Network queueing variation
- Interrupt handling timing
- TCP timer granularity

**Algorithmic rate limiters are too precise** - they use software timers and have very consistent behavior.

### Methodology

```python
# Get inter-packet delays
delays = calculate_inter_packet_delays()

# Filter to "typical" pacing delays (exclude obvious bursts/gaps)
filtered_delays = [d for d in delays if 0.01 < d < 10]

# Calculate statistical properties
mean = average(filtered_delays)
stddev = standard_deviation(filtered_delays)
coefficient_of_variation = (stddev / mean) √ó 100

# Check for clustering around specific values
histogram = bucket_delays(filtered_delays, bucket_size=0.1ms)
top_3_buckets = most_common(histogram, 3)
clustering_pct = sum(top_3_buckets) / total √ó 100
```

### Coefficient of Variation (CoV)

**Definition:**
```
CoV = (standard deviation / mean) √ó 100%
```

**Interpretation:**
- **Low CoV (<20%)**: Very consistent, little variation
- **Moderate CoV (20-80%)**: Some variation
- **High CoV (>80%)**: High variation, natural behavior

### Delay Clustering

We create a histogram of delays with fine granularity (0.1ms buckets).

**Natural TCP:**
```
Delay Histogram:
0.2-0.3ms: ‚ñà‚ñà‚ñà‚ñà (12%)
0.3-0.4ms: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (23%)
0.4-0.5ms: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (18%)
0.5-0.6ms: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (17%)
0.6-0.7ms: ‚ñà‚ñà‚ñà‚ñà (11%)
... (spread across many buckets)

Top 3 buckets: 23% + 18% + 17% = 58%
```

**Algorithmic pacing:**
```
Delay Histogram:
19.9-20.0ms: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (45%)
20.0-20.1ms: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (35%)
20.1-20.2ms: ‚ñà‚ñà‚ñà‚ñà (12%)
... (concentrated in few buckets)

Top 3 buckets: 45% + 35% + 12% = 92%
```

### Metrics Collected

```python
{
  "samples": 1234,
  "avg_delay_ms": 0.523,
  "stddev_ms": 0.678,
  "coefficient_of_variation": 129.6,
  "top_3_clustering_pct": 58.4
}
```

### Interpretation

**Thresholds for algorithmic behavior:**

```
CoV < 20% AND Clustering > 60%:
  ‚Üí Algorithmic pacing CONFIRMED

CoV < 40% AND Clustering > 50%:
  ‚Üí Likely algorithmic pacing

CoV > 80%:
  ‚Üí Natural TCP behavior
```

### Why This Matters

Even if inter-packet delays seem reasonable (e.g., 5ms average), if they're **too consistent**, that proves it's programmatic.

**Example:**

```
Server A (Natural):
  Delays: 4.2, 5.8, 3.7, 6.1, 4.9, 5.3 ms
  Average: 5.0ms
  CoV: 85%
  Interpretation: Natural variation

Server B (Throttled):
  Delays: 4.9, 5.0, 5.1, 5.0, 5.0, 4.9 ms
  Average: 5.0ms
  CoV: 8%
  Interpretation: Algorithmic timer, rate limiting
```

Both have the same average, but Server B is clearly using software pacing.

### Real-World Example

**Legacy Server:**
```
Pacing Analysis:
  Samples: 2341
  Average delay: 0.523ms
  Std Dev: 0.678ms
  CoV: 129.6%
  Top 3 clustering: 58.4%

Interpretation:
  High CoV ‚Üí Natural variation
  Moderate clustering ‚Üí Delays spread across range
  Conclusion: Organic TCP sending behavior
```

**CDN Server (Throttled):**
```
Pacing Analysis:
  Samples: 1987
  Average delay: 20.31ms (excluding bursts)
  Std Dev: 3.45ms
  CoV: 17.0%
  Top 3 clustering: 78.2%

Interpretation:
  Low CoV ‚Üí Very consistent timing
  High clustering ‚Üí 78% of delays in just 3 buckets
  Conclusion: Algorithmic pacing, software rate limiter
```

### The Smoking Gun

When you see:
- **Low CoV** (<20%)
- **High clustering** (>70%)
- **Consistent gap timing** (~20ms)

You can definitively say: **"This is programmatic rate limiting, not network effects or natural TCP dynamics."**

### Implementation Details

```bash
tshark -r file.pcap -T fields \
  -Y "tcp.srcport == SERVER_PORT and tcp.len > 0" \
  -e frame.time_relative
```

Post-processing in Python:
```python
# Calculate delays
delays = []
for i in range(1, len(timestamps)):
    delay_ms = (timestamps[i] - timestamps[i-1]) * 1000
    delays.append(delay_ms)

# Filter to typical pacing range
filtered = [d for d in delays if 0.01 < d < 10]

# Create histogram
histogram = defaultdict(int)
bucket_size = 0.1  # ms
for delay in filtered:
    bucket = round(delay / bucket_size) * bucket_size
    histogram[bucket] += 1

# Find top clusters
sorted_buckets = sorted(histogram.items(), key=lambda x: x[1], reverse=True)
top_3 = sorted_buckets[:3]
top_3_pct = sum(count for _, count in top_3) / len(filtered) * 100
```

---

## Statistical Methods

### Why Statistics Matter

With 5 iterations of each test (Legacy and CDN), we need to:
1. **Aggregate** results properly
2. **Quantify variation** across iterations
3. **Determine statistical significance** of differences

### Measures of Central Tendency

**Mean (Average):**
```
mean = sum(values) / count(values)
```

Pros: Uses all data points
Cons: Sensitive to outliers

**Median:**
```
median = middle value when sorted
```

Pros: Not affected by outliers
Cons: Ignores magnitude of extreme values

**When to use:**
- Use **mean** for normally distributed data
- Use **median** when outliers are present or distribution is skewed

### Measures of Variability

**Standard Deviation (stddev):**
```
variance = sum((value - mean)¬≤) / (count - 1)
stddev = sqrt(variance)
```

Interpretation:
- **Low stddev**: Consistent across iterations
- **High stddev**: Variable results

**Coefficient of Variation (CoV):**
```
CoV = (stddev / mean) √ó 100%
```

Interpretation:
- **<10%**: Very consistent
- **10-30%**: Moderate variation
- **>30%**: High variation

**Why CoV is useful:**
It's **scale-independent**. You can compare:
- Throughput (Mbps) with CoV = 15%
- RTT (ms) with CoV = 20%

And say "throughput is more consistent than RTT"

### Percentiles

**Definition:** The Pth percentile is the value below which P% of observations fall.

**P95 (95th percentile):**
- 95% of values are below this
- Only 5% are higher
- Good for "worst-case" SLAs

**P99 (99th percentile):**
- 99% of values are below this
- Only 1% are higher
- Useful for identifying rare outliers

**Calculation:**
```python
def percentile(data, p):
    sorted_data = sorted(data)
    index = (len(sorted_data) - 1) * p / 100
    floor_index = int(index)

    if floor_index + 1 < len(sorted_data):
        # Interpolate
        lower = sorted_data[floor_index]
        upper = sorted_data[floor_index + 1]
        fraction = index - floor_index
        return lower + fraction * (upper - lower)

    return sorted_data[floor_index]
```

### Comparing Two Groups

When comparing CDN vs Legacy:

**Ratio of Means:**
```
ratio = mean_cdn / mean_legacy
```

Example:
```
Legacy inter-packet delay: 0.523ms
CDN inter-packet delay: 15.234ms
Ratio: 15.234 / 0.523 = 29.1

Interpretation: CDN is 29x slower at sending consecutive packets
```

**Difference in Standard Deviations:**

If both have similar stddev, the difference is consistent across iterations.

```
Legacy: 145 Mbps (¬±12)
CDN: 45 Mbps (¬±8)

Interpretation: CDN is consistently slower (low variation in both)
```

### Statistical Significance

With only 5 iterations each, we can't do formal hypothesis testing, but we can use heuristics:

**Rule of thumb:** If groups' ranges don't overlap, difference is significant.

```
Legacy: 140-160 Mbps (mean ¬± 2√óstddev)
CDN: 40-60 Mbps (mean ¬± 2√óstddev)

No overlap ‚Üí Difference is real, not random variation
```

### Aggregating Across Iterations

For directory analysis:

```python
# Collect metrics from all iterations
legacy_throughputs = [145.2, 148.7, 143.1, 149.3, 144.8]
cdn_throughputs = [43.5, 47.2, 41.8, 46.1, 44.3]

# Calculate aggregated statistics
legacy_mean = mean(legacy_throughputs)  # 146.2
legacy_stddev = stddev(legacy_throughputs)  # 2.6

cdn_mean = mean(cdn_throughputs)  # 44.6
cdn_stddev = stddev(cdn_throughputs)  # 2.1

# Report
print(f"Legacy: {legacy_mean:.1f} Mbps (¬±{legacy_stddev:.1f})")
print(f"CDN: {cdn_mean:.1f} Mbps (¬±{cdn_stddev:.1f})")
```

---

## Diagnosis Logic

### How the Script Diagnoses Issues

The diagnosis follows a **decision tree** based on metric thresholds.

### Decision Tree

```
Start: Comparing CDN vs Legacy performance

‚îú‚îÄ RTT similar?
‚îÇ  ‚îú‚îÄ Yes ‚Üí Network latency NOT the issue
‚îÇ  ‚îî‚îÄ No ‚Üí Note: CDN path has higher latency, but check other metrics
‚îÇ
‚îú‚îÄ Retransmission rate high?
‚îÇ  ‚îú‚îÄ >3% ‚Üí ISSUE: Packet loss on network path
‚îÇ  ‚îî‚îÄ <1% ‚Üí Network path is clean
‚îÇ
‚îú‚îÄ Burst count high? (CDN >100 bursts AND >3x Legacy)
‚îÇ  ‚îú‚îÄ Yes ‚Üí üî¥ CRITICAL: Burst pacing throttling
‚îÇ  ‚îî‚îÄ No ‚Üí Continue checking
‚îÇ
‚îú‚îÄ Pacing precision algorithmic? (CoV <20% AND clustering >60%)
‚îÇ  ‚îú‚îÄ Yes ‚Üí üî¥ CRITICAL: Algorithmic pacing detected
‚îÇ  ‚îî‚îÄ No ‚Üí Continue checking
‚îÇ
‚îú‚îÄ Inter-packet delay high? (CDN >3x Legacy)
‚îÇ  ‚îú‚îÄ Yes ‚Üí üî¥ CRITICAL: Server slow at sustained delivery
‚îÇ  ‚îî‚îÄ No ‚Üí Continue checking
‚îÇ
‚îú‚îÄ Server response latency high? (CDN >2x Legacy AND >10ms)
‚îÇ  ‚îú‚îÄ Yes ‚Üí MEDIUM: Server slow to start responding
‚îÇ  ‚îî‚îÄ No ‚Üí Server responsive
‚îÇ
‚îî‚îÄ Throughput low? (<100 Mbps)
   ‚îú‚îÄ Yes ‚Üí HIGH: Low throughput (SYMPTOM of above issues)
   ‚îî‚îÄ No ‚Üí Performance acceptable
```

### Issue Prioritization

**CRITICAL (Root Causes):**
1. Burst pacing (proves rate limiting algorithm)
2. Algorithmic pacing precision (proves programmatic behavior)
3. Excessive inter-packet delays (proves slow sending)

**MEDIUM (Contributing Factors):**
4. High server response latency
5. Packet loss >1%

**SYMPTOM (Outcome):**
6. Low throughput
7. High throughput variability

### Diagnosis Examples

**Case 1: Clear Throttling**
```
Metrics:
  RTT: Legacy 12ms, CDN 13ms ‚úì (similar)
  Retrans: Legacy 0.2%, CDN 0.3% ‚úì (both low)
  Bursts: Legacy 8, CDN 675 üî¥ (84x ratio)
  Pacing CoV: Legacy 128%, CDN 17% üî¥ (algorithmic)
  Inter-packet: Legacy 0.5ms, CDN 15.2ms üî¥ (30x ratio)
  Throughput: Legacy 145 Mbps, CDN 45 Mbps (symptom)

Diagnosis:
  üî¥ ROOT CAUSE: Server Burst Pacing/Throttling
  üî¥ THROTTLING: Algorithmic Pacing Detected
  üî¥ ROOT CAUSE: CDN Server Slow at Sustained Data Delivery

Recommendation:
  Contact Tanium about CDN rate limiting configuration.
  This is NOT a network issue - server is deliberately pacing.
```

**Case 2: Network Path Issue**
```
Metrics:
  RTT: Legacy 12ms, CDN 85ms ‚ö†Ô∏è (7x higher)
  Retrans: Legacy 0.2%, CDN 4.5% üî¥ (high loss)
  Bursts: Legacy 8, CDN 12 ‚úì (similar)
  Inter-packet: Legacy 0.5ms, CDN 0.7ms ‚úì (similar)
  Throughput: Legacy 145 Mbps, CDN 60 Mbps (reduced)

Diagnosis:
  MEDIUM: High network latency to CDN
  MEDIUM: Elevated packet loss

Recommendation:
  CDN routing issue. Check network path to CDN endpoint.
  Run MTR to identify where packet loss occurs.
  Server behavior is normal, network is the bottleneck.
```

**Case 3: Both Issues**
```
Metrics:
  RTT: Legacy 12ms, CDN 78ms ‚ö†Ô∏è (high)
  Retrans: Legacy 0.2%, CDN 2.3% ‚ö†Ô∏è (moderate)
  Bursts: Legacy 8, CDN 450 üî¥ (56x ratio)
  Inter-packet: Legacy 0.5ms, CDN 12.3ms üî¥ (25x ratio)
  Throughput: Legacy 145 Mbps, CDN 25 Mbps (poor)

Diagnosis:
  üî¥ ROOT CAUSE: Server Burst Pacing/Throttling
  MEDIUM: Elevated packet loss
  MEDIUM: Higher network latency

Recommendation:
  PRIMARY: CDN server throttling
  SECONDARY: CDN network path also suboptimal
  Fix server throttling first (biggest impact).
```

---

## Rate Limiting Algorithms

Understanding HOW rate limiting works helps interpret our metrics.

### Token Bucket Algorithm

**Most common** rate limiting approach.

**How it works:**
```
1. Bucket holds tokens (capacity C)
2. Tokens added at rate R per second
3. To send X bytes, consume X tokens
4. If tokens available:
     - Consume tokens
     - Send data immediately
5. If tokens not available:
     - Wait until tokens accumulate
     - Send when sufficient tokens
```

**Example:**
```
Rate: 50 Mbps = 6,250,000 bytes/sec
Bucket capacity: 100,000 bytes
Token rate: 6,250,000 bytes/sec = 6,250 bytes/ms

Timeline:
T=0ms:  Bucket has 100,000 tokens (full)
        Send 100,000 bytes in burst
        Bucket now has 0 tokens

T=1ms:  Tokens added: 6,250
        Send 6,250 bytes

T=2ms:  Tokens added: 6,250
        Send 6,250 bytes

... continuous at token rate ...

If packets queued faster than token rate:
T=10ms: Need 50,000 bytes, only 6,250 tokens available
        Wait until T=18ms (accumulate 50,000 tokens)
        Creates 8ms GAP
        Send 50,000 bytes in BURST
```

**Result:** Burst-gap-burst-gap pattern

**Signature in metrics:**
- High burst count
- Consistent gap timing
- Low pacing CoV

### Leaky Bucket Algorithm

**Alternative** approach, smoother output.

**How it works:**
```
1. Bucket holds queued data (capacity C)
2. Data "leaks" out at constant rate R
3. Incoming data fills bucket
4. If bucket full, new data dropped/delayed
```

**Example:**
```
Rate: 50 Mbps = 6,250 bytes/ms
Bucket capacity: 100,000 bytes

Timeline:
T=0ms:  100KB arrives, bucket fills to 100KB
T=1ms:  6,250 bytes leak out
T=2ms:  6,250 bytes leak out
... smooth constant rate ...
```

**Result:** More consistent inter-packet delays

**Signature in metrics:**
- Fewer distinct bursts
- Very consistent inter-packet delays
- Very low pacing CoV (<10%)

### Fair Queuing

**Sophisticated** approach for multi-user systems.

Divides bandwidth fairly among active connections.

**Impact on single connection:**
- Can behave like token bucket
- Rate depends on number of active users
- Variable performance

### Detection Strategy

**Token Bucket indicators:**
- Burst count: >100
- Gap timing: Consistent (¬±20%)
- Pacing CoV: 15-30%

**Leaky Bucket indicators:**
- Burst count: <50
- Gap timing: Very consistent (¬±5%)
- Pacing CoV: <10%

**No Rate Limiting:**
- Burst count: <10
- Gap timing: Highly variable
- Pacing CoV: >80%

---

## CDN vs Legacy Comparison

### Comparison Methodology

When analyzing a directory with multiple PCAPs:

1. **Categorize files** by filename:
   - Contains "legacy" ‚Üí Legacy group
   - Contains "cdn" ‚Üí CDN group

2. **Analyze each file** independently

3. **Aggregate metrics** across iterations:
   - Calculate mean ¬± stddev for each metric
   - Per group (Legacy and CDN)

4. **Compare groups**:
   - Calculate ratios (CDN/Legacy)
   - Identify significant differences

5. **Diagnose**:
   - Apply decision tree logic
   - Generate recommendations

### Expected Legacy Baseline

**Healthy Legacy server should show:**

```
Connection:
  Handshake time: <20ms

Network:
  RTT: <30ms
  Retransmission rate: <0.5%

Server behavior:
  Inter-packet delay: <1ms average
  Burst count: <20
  Pacing CoV: >80%

Throughput:
  Average: >100 Mbps
  CoV: <20%
```

### CDN Comparison Scenarios

**Scenario A: CDN Performing Well**
```
All metrics within 20% of Legacy
Conclusion: CDN equivalent to Legacy, no issues
```

**Scenario B: CDN Path Latency**
```
RTT: 2-3x Legacy
Retrans: Similar
Server behavior: Similar
Throughput: 70-80% of Legacy

Conclusion: Geographic distance or routing, but server behavior normal
```

**Scenario C: CDN Throttled (Most Common)**
```
RTT: Similar
Retrans: Similar
Burst count: 10-100x Legacy
Inter-packet delay: 10-30x Legacy
Pacing CoV: <20% (vs Legacy >80%)
Throughput: 30-50% of Legacy

Conclusion: Clear server-side throttling
```

### Quantifying the Impact

**Throughput loss calculation:**

```
Legacy throughput: 145 Mbps
CDN throughput: 45 Mbps

Throughput loss: 145 - 45 = 100 Mbps (69% reduction)
```

**Time impact on downloads:**

```
File size: 1 GB

Legacy download time:
  1,000 MB √ó 8 bits/byte / (145 Mbps) = 55.2 seconds

CDN download time:
  1,000 MB √ó 8 bits/byte / (45 Mbps) = 177.8 seconds

Additional time: 177.8 - 55.2 = 122.6 seconds (3.2x longer)
```

### Real-World Example

**Actual analysis output:**

```
[LEGACY] Summary across 5 captures:
  Throughput: 146.2 Mbps (¬±2.6)
  RTT: 12.3 ms (¬±1.2)
  Retransmission Rate: 0.23% (¬±0.05%)
  Inter-Packet Delay: 0.52 ms (¬±0.08)
  Burst Count: 8 bursts (¬±2)
  Burst Gap: 125.1 ms (¬±23.4)
  Pacing CoV: 128.3% (¬±15.2)
  Pacing Clustering: 58.4% (¬±6.7)

[CDN] Summary across 5 captures:
  Throughput: 44.6 Mbps (¬±2.1)
  RTT: 13.5 ms (¬±1.8)
  Retransmission Rate: 0.19% (¬±0.04%)
  Inter-Packet Delay: 15.23 ms (¬±1.34)
  Burst Count: 675 bursts (¬±89)
  Burst Gap: 20.3 ms (¬±2.1)
  Pacing CoV: 17.4% (¬±3.2)
  Pacing Clustering: 78.2% (¬±5.3)

DIAGNOSIS:
üî¥ ROOT CAUSE: Server Burst Pacing/Throttling
   CDN bursts: 675 vs Legacy: 8 (84.4x more)
   CDN gap: 20.3ms vs Legacy: 125.1ms (consistent small gaps)
   - CDN server sends data in many small bursts with gaps
   - This is characteristic of algorithmic rate limiting
   - Token bucket with ~50 Mbps limit

üî¥ THROTTLING: Algorithmic Pacing Detected
   CoV: 17.4% vs Legacy: 128.3% (7.4x more precise)
   Clustering: 78.2% vs Legacy: 58.4% (delays concentrated)
   - Inter-packet delays are too precise and clustered
   - This precision indicates programmatic rate limiting

üî¥ ROOT CAUSE: CDN Server Slow at Sustained Data Delivery
   CDN delay: 15.23ms vs Legacy: 0.52ms (29.3x slower)
   - The CDN server pauses 29x longer between packets
   - NOT network latency (RTT is similar: 13.5ms vs 12.3ms)
   - Server-side rate limiting confirmed

RECOMMENDATIONS:
  1. Contact Tanium support about CDN rate limiting configuration
  2. Request per-connection bandwidth limit increase (currently ~45 Mbps)
  3. Investigate if CDN has tiering (paid vs free performance)
  4. Short-term workaround: Use multiple parallel connections to bypass per-connection limit
  5. Consider requesting CDN bypass option for high-performance customers

IMPACT:
  - 69% throughput reduction (146 Mbps ‚Üí 45 Mbps)
  - 3.3x longer download times
  - Consistent across all 5 test iterations
  - Affects all CDN users (not environment-specific)
```

---

## Case Studies

### Case Study 1: Token Bucket Throttling

**Scenario:** CDN download via Tanium client, 1GB file

**Observations:**
```
Basic Stats:
  Duration: 178 seconds
  Throughput: 44.9 Mbps

Network Metrics:
  RTT: 14.2ms
  Retransmissions: 0.18%
  (Both healthy)

Server Metrics:
  Inter-packet delay: 14.7ms avg
  Burst count: 823
  Avg burst size: 3.2 packets
  Avg gap: 18.5ms
  Pacing CoV: 19.3%
  Clustering: 74.6%
```

**Analysis:**

1. **Network is healthy**: Low RTT, minimal packet loss
2. **Burst pattern is extreme**: 823 bursts in 178 seconds = 4.6 bursts/second
3. **Gap timing very consistent**: 18.5ms ¬± 19.3% ‚Üí most gaps 15-22ms
4. **Burst size consistent**: ~3 packets (4,380 bytes) per burst
5. **Delays clustered**: 74.6% in top 3 buckets ‚Üí algorithmic

**Diagnosis:**

Token bucket rate limiter with:
- Rate limit: ~45 Mbps
- Bucket size: ~4,400 bytes
- Token refill: ~4,400 bytes per 18.5ms = 237,838 bytes/sec = 1.9 Mbps per burst

Math check:
- 4.6 bursts/sec √ó 4,400 bytes/burst √ó 8 bits/byte = 162,000 bits/sec = 0.162 Mbps
- Wait, that's wrong...

Actually:
- Total transfer: 1 GB in 178 sec = 44.9 Mbps ‚úì
- Burst capacity: allows bursts up to 4,400 bytes
- But average rate enforced at 45 Mbps

**Smoking gun:** The 18.5ms gap is the token bucket refill time.

### Case Study 2: Network Path Issues

**Scenario:** CDN endpoint routed through suboptimal path

**Observations:**
```
Basic Stats:
  Duration: 95 seconds
  Throughput: 84.2 Mbps

Network Metrics:
  RTT: 76.4ms (vs Legacy 12.3ms)
  Retransmissions: 3.2% (vs Legacy 0.2%)
  Duplicate ACKs: 87

Server Metrics:
  Inter-packet delay: 0.89ms
  Burst count: 15
  Pacing CoV: 95.3%
```

**Analysis:**

1. **RTT is 6x higher**: Indicates distant or routed path
2. **Packet loss is elevated**: 3.2% retransmission rate
3. **But server behavior is normal**: Low inter-packet delay, few bursts, high CoV

**Diagnosis:**

Network path bottleneck, NOT server throttling.

**Recommendations:**
- Investigate CDN endpoint selection (possibly routed internationally)
- Check for network congestion or routing issues
- Run traceroute/MTR to identify hop causing delays
- Server is behaving normally, so focus on network

### Case Study 3: Perfect Storm (Both Issues)

**Scenario:** Throttled CDN over poor network path

**Observations:**
```
Basic Stats:
  Duration: 285 seconds
  Throughput: 28.1 Mbps

Network Metrics:
  RTT: 68.3ms
  Retransmissions: 2.1%

Server Metrics:
  Inter-packet delay: 22.3ms
  Burst count: 1,247
  Pacing CoV: 14.2%
```

**Analysis:**

Both issues present:
- High RTT + packet loss = network path problem
- High burst count + low CoV = server throttling

**Diagnosis:**

Multiple bottlenecks compounding:
1. **Primary**: Server throttling (~40-50 Mbps limit)
2. **Secondary**: Poor network path (reduces effective rate further)

**Impact breakdown:**
```
Ideal throughput: 150 Mbps (wire speed)
After network path: ~100 Mbps (RTT/loss impact)
After throttling: 28 Mbps (rate limiter enforced)

Network accounts for ~33% loss
Throttling accounts for ~72% loss
Combined: 81% loss
```

**Recommendations:**
1. Fix server throttling first (biggest impact)
2. Then address network path issues
3. Don't assume network is the only problem

---

## Troubleshooting Guide

### Quick Diagnostic Flowchart

```
Is throughput poor (<100 Mbps)?
‚îú‚îÄ NO ‚Üí Performance acceptable, no action needed
‚îî‚îÄ YES ‚Üì

Is RTT high (>50ms)?
‚îú‚îÄ YES ‚Üí Network latency is a factor
‚îÇ        Check routing, endpoint selection
‚îî‚îÄ NO ‚Üì

Is retransmission rate high (>1%)?
‚îú‚îÄ YES ‚Üí Packet loss is a factor
‚îÇ        Check network path, firewalls
‚îî‚îÄ NO ‚Üì

Is burst count high (>100)?
‚îú‚îÄ YES ‚Üí üî¥ Server throttling detected
‚îÇ        Check pacing precision
‚îî‚îÄ NO ‚Üì

Is inter-packet delay high (>5ms)?
‚îú‚îÄ YES ‚Üí üî¥ Server sending slowly
‚îÇ        Investigate server performance
‚îî‚îÄ NO ‚Üì

Unclear cause - review all metrics
```

### Common Misdiagnoses

**Mistake 1: "The network is slow"**

**Evidence:**
- Low throughput
- Small TCP windows

**Actual cause:**
- Server throttling with burst pacing
- Windows are small BECAUSE server sends slowly

**How to confirm:**
- Check RTT (is it actually high?)
- Check inter-packet delays (server pausing?)
- Check burst patterns (algorithmic?)

---

**Mistake 2: "We need bigger TCP windows"**

**Evidence:**
- Small receive windows advertised
- Low throughput

**Actual cause:**
- Server throttling limits sending rate
- Client doesn't need big window if server sends slowly

**How to confirm:**
- Check inter-packet delays (if >5ms, server is the bottleneck)
- Increasing window won't help if server is rate limiting

---

**Mistake 3: "It's packet loss"**

**Evidence:**
- Some retransmissions
- Variable throughput

**Actual cause:**
- Minor packet loss (<1%) is normal
- Throughput variability due to burst pacing

**How to confirm:**
- Check retransmission rate (if <1%, not the main issue)
- Check burst patterns (high variability = throttling)

---

**Mistake 4: "The CDN is just far away"**

**Evidence:**
- Higher RTT to CDN
- Lower throughput

**Actual cause:**
- RTT accounts for some loss
- But burst pacing is the main factor

**How to confirm:**
- Calculate BDP (Bandwidth-Delay Product)
- With 50ms RTT and 64KB window, can still achieve 10+ Mbps
- If throughput is much lower, RTT isn't the only issue

### Interpreting Conflicting Signals

**Scenario:** Good network metrics, poor throughput

```
RTT: 15ms ‚úì
Retrans: 0.3% ‚úì
Throughput: 35 Mbps ‚úó
```

**Diagnosis:** Server-side issue (check burst patterns, inter-packet delays)

---

**Scenario:** Poor network metrics, good server behavior

```
RTT: 85ms ‚ö†Ô∏è
Retrans: 3.5% ‚ö†Ô∏è
Inter-packet delay: 0.7ms ‚úì
Burst count: 12 ‚úì
```

**Diagnosis:** Network path issue (server is fine, route is bad)

---

**Scenario:** Everything looks OK, but throughput is low

```
RTT: 12ms ‚úì
Retrans: 0.2% ‚úì
Inter-packet delay: 1.2ms ‚úì (seems OK)
Burst count: 45 ‚ö†Ô∏è (moderate)
Throughput: 60 Mbps ‚ö†Ô∏è
```

**Diagnosis:** Mild throttling (not severe, but present). Check pacing precision for algorithmic behavior.

### When to Escalate

**Contact Network Team:**
- High RTT (>50ms) to CDN endpoint
- High packet loss (>1%) consistently
- Routing issues visible in traceroute

**Contact Vendor (Tanium):**
- Burst pacing confirmed (>100 bursts)
- Algorithmic pacing precision (CoV <20%)
- Inter-packet delays 5x+ higher than baseline
- Consistent across all tests

**Both:**
- Multiple issues compounding
- Unclear root cause after analysis

---

## Appendix: Technical Details

### Tshark Commands Reference

**Basic packet info:**
```bash
tshark -r file.pcap -T fields \
  -e frame.number \
  -e frame.time_relative \
  -e frame.len
```

**TCP specific:**
```bash
tshark -r file.pcap -T fields -Y tcp \
  -e tcp.srcport \
  -e tcp.dstport \
  -e tcp.len \
  -e tcp.window_size \
  -e tcp.flags.syn \
  -e tcp.flags.ack
```

**RTT analysis:**
```bash
tshark -r file.pcap -T fields \
  -Y "tcp.analysis.ack_rtt" \
  -e frame.time_relative \
  -e tcp.analysis.ack_rtt
```

**Retransmissions:**
```bash
tshark -r file.pcap -Y "tcp.analysis.retransmission"
tshark -r file.pcap -Y "tcp.analysis.fast_retransmission"
```

**Data packets from server:**
```bash
tshark -r file.pcap -T fields \
  -Y "tcp.srcport == 443 and tcp.len > 0" \
  -e frame.time_relative \
  -e tcp.len
```

### Python Processing Examples

**Calculate inter-packet delays:**
```python
import subprocess

def get_packet_times(pcap_file, server_port):
    cmd = [
        'tshark', '-r', pcap_file,
        '-T', 'fields',
        '-Y', f'tcp.srcport == {server_port} and tcp.len > 0',
        '-e', 'frame.time_relative'
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    times = []

    for line in result.stdout.strip().split('\n')[1:]:  # Skip header
        if line:
            times.append(float(line))

    return times

def calculate_delays(times):
    delays = []
    for i in range(1, len(times)):
        delay_ms = (times[i] - times[i-1]) * 1000
        delays.append(delay_ms)
    return delays

# Usage
times = get_packet_times('capture.pcap', 443)
delays = calculate_delays(times)

import statistics
print(f"Average delay: {statistics.mean(delays):.3f} ms")
print(f"Median delay: {statistics.median(delays):.3f} ms")
print(f"P95 delay: {percentile(delays, 95):.3f} ms")
```

**Burst detection:**
```python
def detect_bursts(delays, threshold_ms=10):
    bursts = []
    current_burst = []
    gaps = []

    for i, delay in enumerate(delays):
        if delay < threshold_ms:
            current_burst.append(i)
        else:
            if current_burst:
                bursts.append(len(current_burst) + 1)  # +1 for first packet
                gaps.append(delay)
                current_burst = []

    if current_burst:
        bursts.append(len(current_burst) + 1)

    return bursts, gaps

# Usage
bursts, gaps = detect_bursts(delays)
print(f"Total bursts: {len(bursts)}")
print(f"Average burst size: {statistics.mean(bursts):.1f} packets")
print(f"Average gap: {statistics.mean(gaps):.2f} ms")
```

### Calculating Bandwidth-Delay Product (BDP)

**Formula:**
```
BDP = Bandwidth √ó RTT
```

**Purpose:** Maximum amount of data "in flight" on the network.

**Example:**
```
Bandwidth: 100 Mbps = 12,500,000 bytes/sec
RTT: 50ms = 0.05 seconds

BDP = 12,500,000 √ó 0.05 = 625,000 bytes = 610 KB
```

**Interpretation:**

TCP window must be ‚â• BDP to fully utilize bandwidth.

With 64 KB window (common default):
```
Max throughput = Window / RTT
              = 65,536 bytes / 0.05 sec
              = 1,310,720 bytes/sec
              = 10.5 Mbps
```

Even with 100 Mbps available, limited to 10.5 Mbps by window size.

**But:** With window scaling (typical now), windows can be much larger (megabytes), so this is rarely the bottleneck unless RTT is very high (>200ms).

---

## Summary

This guide has covered:

1. **TCP Fundamentals** - How TCP works in download scenarios
2. **All Metrics** - What each measures and why it matters
3. **Statistical Methods** - How to interpret and aggregate data
4. **Diagnosis Logic** - How to identify root causes
5. **Rate Limiting** - How throttling algorithms work
6. **Comparison Methods** - How to compare CDN vs Legacy
7. **Case Studies** - Real-world examples
8. **Troubleshooting** - How to diagnose issues correctly

### Key Takeaways

**For Performance Analysis:**
- Look at **root causes** (server behavior) not just symptoms (throughput)
- **RTT and throughput are different** - low RTT doesn't guarantee high throughput
- **TCP windows are reactive** - small windows are a symptom, not a cause

**For Throttling Detection:**
- **Burst patterns** (>100 bursts) prove rate limiting
- **Pacing precision** (CoV <20%, clustering >60%) proves algorithmic behavior
- **Inter-packet delays** (10x+ higher than baseline) prove slow sending

**For Vendor Discussions:**
- Use **data** not assumptions ("here's proof of burst pacing")
- Be **specific** ("675 bursts with 20ms gaps, CoV 17%")
- Request **configuration review** ("per-connection rate limits")

### Complete Workflow

**Step 1: Generate PCAPs**
```bash
# Run the performance test to generate packet captures
python3 tanium_download_perf_test.py

# This will create a directory: tanium_pcaps_YYYYMMDD_HHMMSS/
# Containing 5 legacy and 5 CDN download captures
```

**Step 2: Analyze PCAPs**
```bash
# Analyze the entire directory (recommended)
python3 analyze_tanium_pcaps.py --pcap-dir tanium_pcaps_YYYYMMDD_HHMMSS/

# This produces:
# - Console output with comparison and diagnosis
# - JSON file: pcap_analysis_<timestamp>.json with detailed metrics

# Or analyze a single file
python3 analyze_tanium_pcaps.py --pcap-file legacy_iteration_1.pcap --server-port 17472
python3 analyze_tanium_pcaps.py --pcap-file cdn_iteration_1.pcap --server-port 443
```

**Step 3: Interpret Results**
- Review the comparison summary (CDN vs Legacy)
- Check the diagnosis section for root causes
- Use this guide to understand each metric
- Share results with Tanium support if throttling detected

### Quick Reference

**Script**: `analyze_tanium_pcaps.py`
**Input**: PCAPs from `tanium_download_perf_test.py`
**Output**: Console analysis + JSON file
**Requirements**: tshark (Wireshark CLI)

---

**Document Version:** 2.0
**Last Updated:** 2025
**Script:** analyze_tanium_pcaps.py
**PCAP Source:** tanium_download_perf_test.py
**Author:** Network Performance Analysis Team
